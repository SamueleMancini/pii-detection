{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\Desktop\\nlp-project\\cubo_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import auxiliary as aux\n",
    "from tqdm import tqdm\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in epoch:   0%|          | 0/18651 [00:00<?, ?it/s]c:\\Users\\samue\\Desktop\\nlp-project\\auxiliary.py:259: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  stacked_tensors1 = torch.stack([torch.tensor(i) for i in output1])\n",
      "c:\\Users\\samue\\Desktop\\nlp-project\\auxiliary.py:262: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  stacked_tensors2 = torch.stack([torch.tensor(i) for i in output2])\n",
      "Steps in epoch:   3%|▎         | 539/18651 [00:49<27:32, 10.96it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from auxiliary import ensembler, json_to_Dataset_ensemble\n",
    "from tqdm import tqdm\n",
    "\n",
    "class KingBert(nn.Module):\n",
    "    def __init__(self, distilbert_tuned, albert_tuned):\n",
    "        super().__init__()\n",
    "        self.distilbert = distilbert_tuned\n",
    "        self.albert = albert_tuned\n",
    "\n",
    "        for distilbert_param in self.distilbert.parameters():\n",
    "            distilbert_param.requires_grad = False\n",
    "\n",
    "        for albert_param in self.albert.parameters():\n",
    "            albert_param.requires_grad = False \n",
    "        \n",
    "        self.alpha = nn.Parameter(0.5 * torch.ones(47), requires_grad=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, distilbert_input_ids, albert_input_ids, distil_attention_mask, alb_attention_mask, distilbert_word_ids, albert_word_ids):\n",
    "        distilbert_output = self.distilbert(input_ids=distilbert_input_ids, attention_mask=distil_attention_mask)\n",
    "        albert_output = self.albert(input_ids=albert_input_ids, attention_mask=alb_attention_mask)\n",
    "        distilbert_fixed, albert_fixed = aux.ensembler(distilbert_output['logits'].squeeze(), albert_output['logits'].squeeze(), distilbert_word_ids.squeeze(), albert_word_ids.squeeze())\n",
    "\n",
    "        distilbert_fixed = self.softmax(distilbert_fixed)\n",
    "        albert_fixed = self.softmax(albert_fixed)\n",
    "\n",
    "        final_output = distilbert_fixed * self.alpha + albert_fixed * (torch.ones(47) - self.alpha)\n",
    "\n",
    "        return self.softmax(final_output)\n",
    "\n",
    "train_dataset = aux.json_to_Dataset_ensemble('datasets/ensemble_train.json')\n",
    "\n",
    "distilbert_tuned = AutoModelForTokenClassification.from_pretrained('models/distilbert1')\n",
    "albert_tuned = AutoModelForTokenClassification.from_pretrained('models/albert1')\n",
    "\n",
    "kingbert_model = KingBert(distilbert_tuned, albert_tuned)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(kingbert_model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(len(train_dataset)), desc=\"Steps in epoch\"):\n",
    "        try:\n",
    "\n",
    "            item = train_dataset[i]\n",
    "            \n",
    "            distilbert_input_ids = torch.tensor(item['distilbert_inputids']).unsqueeze(0)\n",
    "            albert_input_ids = torch.tensor(item['albert_inputids']).unsqueeze(0)\n",
    "            distil_attention_mask = torch.tensor(item['distilbert_attention_masks']).unsqueeze(0)\n",
    "            alb_attention_mask = torch.tensor(item['albert_attention_masks']).unsqueeze(0)\n",
    "            distilbert_word_ids = torch.tensor([-100] + item['distilbert_wordids'][1:-1] + [-100]).unsqueeze(0)\n",
    "            albert_word_ids = torch.tensor([-100] + item['albert_wordids'][1:-1] + [-100]).unsqueeze(0)\n",
    "            targets = torch.tensor(item['spacy_labels']).unsqueeze(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = kingbert_model(distilbert_input_ids, albert_input_ids, distil_attention_mask, alb_attention_mask, distilbert_word_ids, albert_word_ids)\n",
    "            \n",
    "            ohe_targets = torch.zeros(output.shape[0], output.shape[1])\n",
    "            for i,j in enumerate(targets):\n",
    "                ohe_targets[i][j] = 1\n",
    "\n",
    "            loss = criterion(output, ohe_targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "torch.save(kingbert_model.state_dict(), 'model_state.pth')\n",
    "\n",
    "print('Training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01:  11%|█         | 2012/18651 [01:29<12:43, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01:  34%|███▎      | 6266/18651 [04:47<11:07, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01:  57%|█████▋    | 10645/18651 [08:05<07:17, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01:  82%|████████▏ | 15368/18651 [11:45<02:24, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01:  94%|█████████▍| 17593/18651 [13:26<00:49, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 18651/18651 [14:15<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02:  11%|█         | 2009/18651 [01:29<14:46, 18.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02:  34%|███▎      | 6267/18651 [04:47<10:35, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02:  57%|█████▋    | 10645/18651 [08:11<07:50, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02:  82%|████████▏ | 15368/18651 [11:48<02:14, 24.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02:  94%|█████████▍| 17592/18651 [13:30<00:56, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 18651/18651 [14:22<00:00, 21.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 3.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03:  11%|█         | 2011/18651 [01:35<13:29, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03:  34%|███▎      | 6267/18651 [04:56<11:33, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03:  57%|█████▋    | 10646/18651 [08:27<07:15, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03:  82%|████████▏ | 15366/18651 [12:15<02:31, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03:  94%|█████████▍| 17593/18651 [14:02<00:53, 19.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 18651/18651 [14:51<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 3.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04:  11%|█         | 2011/18651 [01:34<13:33, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04:  34%|███▎      | 6266/18651 [05:00<12:35, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04:  57%|█████▋    | 10645/18651 [08:28<07:59, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04:  82%|████████▏ | 15368/18651 [12:16<02:23, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04:  94%|█████████▍| 17593/18651 [14:04<00:55, 19.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 18651/18651 [14:56<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 3.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05:  11%|█         | 2011/18651 [01:37<13:35, 20.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05:  34%|███▎      | 6266/18651 [05:01<11:32, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05:  57%|█████▋    | 10645/18651 [08:33<07:16, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05:  82%|████████▏ | 15368/18651 [12:24<02:23, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05:  94%|█████████▍| 17592/18651 [14:10<00:51, 20.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 18651/18651 [14:59<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06:  11%|█         | 2012/18651 [01:35<13:30, 20.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06:  34%|███▎      | 6266/18651 [04:59<12:08, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06:  57%|█████▋    | 10646/18651 [08:28<08:23, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06:  82%|████████▏ | 15366/18651 [12:16<02:34, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06:  94%|█████████▍| 17593/18651 [14:02<00:57, 18.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 18651/18651 [14:55<00:00, 20.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07:  11%|█         | 2011/18651 [01:35<13:31, 20.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07:  34%|███▎      | 6266/18651 [04:58<11:22, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07:  57%|█████▋    | 10645/18651 [08:31<07:19, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07:  82%|████████▏ | 15366/18651 [12:19<02:34, 21.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07:  94%|█████████▍| 17592/18651 [14:05<00:52, 20.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 18651/18651 [14:54<00:00, 20.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08:  11%|█         | 2010/18651 [01:37<13:30, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08:  34%|███▎      | 6266/18651 [05:02<12:11, 16.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08:  57%|█████▋    | 10645/18651 [08:31<09:08, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08:  82%|████████▏ | 15366/18651 [12:22<02:30, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08:  94%|█████████▍| 17591/18651 [14:09<00:54, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 18651/18651 [15:01<00:00, 20.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09:  11%|█         | 2011/18651 [01:36<13:57, 19.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09:  34%|███▎      | 6267/18651 [04:58<11:21, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09:  57%|█████▋    | 10645/18651 [08:30<07:22, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09:  82%|████████▏ | 15368/18651 [12:19<02:33, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09:  94%|█████████▍| 17592/18651 [14:04<00:50, 20.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 18651/18651 [14:54<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  11%|█         | 2009/18651 [01:36<14:10, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  34%|███▎      | 6266/18651 [05:00<11:45, 17.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  57%|█████▋    | 10645/18651 [08:30<07:35, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  82%|████████▏ | 15368/18651 [12:16<02:26, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  94%|█████████▍| 17593/18651 [14:02<00:53, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 18651/18651 [14:54<00:00, 20.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  11%|█         | 2011/18651 [01:37<13:30, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  34%|███▎      | 6266/18651 [05:02<11:20, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  57%|█████▋    | 10645/18651 [08:35<07:00, 19.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  82%|████████▏ | 15368/18651 [12:23<02:33, 21.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  94%|█████████▍| 17592/18651 [14:10<00:55, 19.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 18651/18651 [15:00<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  11%|█         | 2011/18651 [01:38<14:03, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  34%|███▎      | 6266/18651 [05:04<12:24, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  57%|█████▋    | 10645/18651 [08:32<08:19, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  82%|████████▏ | 15366/18651 [12:20<02:32, 21.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  94%|█████████▍| 17593/18651 [14:07<00:53, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 18651/18651 [14:59<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 3.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:  11%|█         | 2012/18651 [01:36<14:09, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:  34%|███▎      | 6267/18651 [05:02<11:15, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:  57%|█████▋    | 10646/18651 [08:37<07:37, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:  82%|████████▏ | 15366/18651 [12:25<02:38, 20.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:  94%|█████████▍| 17592/18651 [14:12<00:52, 20.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 18651/18651 [15:02<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 3.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  11%|█         | 2012/18651 [01:36<12:56, 21.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  34%|███▎      | 6267/18651 [05:02<11:39, 17.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  57%|█████▋    | 10645/18651 [08:29<07:51, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  82%|████████▏ | 15369/18651 [12:17<02:29, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  94%|█████████▍| 17593/18651 [14:03<00:53, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 18651/18651 [14:53<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 3.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:  11%|█         | 2009/18651 [01:36<14:26, 19.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:  34%|███▎      | 6266/18651 [04:59<11:49, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:  57%|█████▋    | 10645/18651 [08:29<07:48, 17.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:  82%|████████▏ | 15366/18651 [12:14<02:45, 19.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:  94%|█████████▍| 17593/18651 [14:01<00:56, 18.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 18651/18651 [14:52<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 3.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16:  11%|█         | 2009/18651 [01:35<15:34, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16:  34%|███▎      | 6266/18651 [05:01<12:07, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16:  57%|█████▋    | 10645/18651 [08:29<07:14, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16:  82%|████████▏ | 15368/18651 [12:18<02:22, 23.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16:  94%|█████████▍| 17592/18651 [14:03<00:50, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 18651/18651 [14:54<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 3.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:  11%|█         | 2009/18651 [01:36<14:45, 18.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:  34%|███▎      | 6267/18651 [05:01<11:22, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:  57%|█████▋    | 10646/18651 [08:32<07:36, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:  82%|████████▏ | 15366/18651 [12:18<02:45, 19.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:  94%|█████████▍| 17593/18651 [14:06<00:52, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 18651/18651 [14:55<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 3.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:  11%|█         | 2010/18651 [01:35<14:06, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:  34%|███▎      | 6267/18651 [05:00<12:26, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:  57%|█████▋    | 10645/18651 [08:30<08:40, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:  82%|████████▏ | 15368/18651 [12:19<02:17, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:  94%|█████████▍| 17593/18651 [14:04<00:52, 19.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 18651/18651 [14:53<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 3.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:  11%|█         | 2011/18651 [01:36<13:46, 20.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:  34%|███▎      | 6267/18651 [05:02<10:54, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:  57%|█████▋    | 10645/18651 [08:33<07:42, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:  82%|████████▏ | 15366/18651 [12:19<02:40, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:  94%|█████████▍| 17592/18651 [14:07<00:53, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 18651/18651 [14:57<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 3.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:  11%|█         | 2011/18651 [01:36<13:32, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 2007 due to error: The size of tensor a (70) must match the size of tensor b (69) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:  34%|███▎      | 6267/18651 [04:59<11:32, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 6263 due to error: The size of tensor a (262) must match the size of tensor b (250) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:  57%|█████▋    | 10645/18651 [08:28<07:42, 17.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 10642 due to error: The size of tensor a (345) must match the size of tensor b (268) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:  82%|████████▏ | 15366/18651 [12:16<02:17, 23.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 15364 due to error: The size of tensor a (98) must match the size of tensor b (97) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:  94%|█████████▍| 17592/18651 [14:02<00:50, 20.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 17588 due to error: The size of tensor a (274) must match the size of tensor b (273) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 18651/18651 [14:52<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 3.0582\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from tqdm import tqdm\n",
    "import auxiliary as aux\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset loading\n",
    "train_dataset = aux.json_to_Dataset_ensemble('datasets/ensemble_train.json')\n",
    "\n",
    "# Load fine-tuned base models\n",
    "distilbert_tuned = AutoModelForTokenClassification.from_pretrained('models/distilbert1').to(device)\n",
    "albert_tuned = AutoModelForTokenClassification.from_pretrained('models/albert1').to(device)\n",
    "\n",
    "# Ensembler model\n",
    "class KingBert(nn.Module):\n",
    "    def __init__(self, distilbert_tuned, albert_tuned):\n",
    "        super().__init__()\n",
    "        self.distilbert = distilbert_tuned\n",
    "        self.albert = albert_tuned\n",
    "\n",
    "        for p in self.distilbert.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.albert.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.alpha = nn.Parameter(0.5 * torch.ones(47, device=device), requires_grad=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, distilbert_input_ids, albert_input_ids,\n",
    "                distil_attention_mask, alb_attention_mask,\n",
    "                distilbert_word_ids, albert_word_ids):\n",
    "\n",
    "        distilbert_output = self.distilbert(input_ids=distilbert_input_ids, attention_mask=distil_attention_mask)\n",
    "        albert_output = self.albert(input_ids=albert_input_ids, attention_mask=alb_attention_mask)\n",
    "\n",
    "        distilbert_logits = distilbert_output['logits'].squeeze()\n",
    "        albert_logits = albert_output['logits'].squeeze()\n",
    "        distilbert_word_ids = distilbert_word_ids.squeeze()\n",
    "        albert_word_ids = albert_word_ids.squeeze()\n",
    "\n",
    "        distilbert_fixed, albert_fixed = aux.ensembler(\n",
    "            distilbert_logits, albert_logits,\n",
    "            distilbert_word_ids, albert_word_ids\n",
    "        )\n",
    "\n",
    "        distilbert_fixed = distilbert_fixed.to(self.alpha.device)\n",
    "        albert_fixed = albert_fixed.to(self.alpha.device)\n",
    "\n",
    "        distilbert_fixed = self.softmax(distilbert_fixed)\n",
    "        albert_fixed = self.softmax(albert_fixed)\n",
    "\n",
    "        alpha = self.alpha\n",
    "        one_minus_alpha = (1.0 - alpha).to(alpha.device)  # ensure same device\n",
    "\n",
    "        combined = distilbert_fixed * alpha + albert_fixed * one_minus_alpha\n",
    "        return self.softmax(combined)\n",
    "\n",
    "# Instantiate model\n",
    "kingbert_model = KingBert(distilbert_tuned, albert_tuned).to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam([kingbert_model.alpha], lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    kingbert_model.train()\n",
    "\n",
    "    for i in tqdm(range(len(train_dataset)), desc=f\"Epoch {epoch+1:02d}\"):\n",
    "        try:\n",
    "            item = train_dataset[i]\n",
    "\n",
    "            distilbert_input_ids = torch.tensor(item['distilbert_inputids']).unsqueeze(0).to(device)\n",
    "            albert_input_ids = torch.tensor(item['albert_inputids']).unsqueeze(0).to(device)\n",
    "            distil_attention_mask = torch.tensor(item['distilbert_attention_masks']).unsqueeze(0).to(device)\n",
    "            alb_attention_mask = torch.tensor(item['albert_attention_masks']).unsqueeze(0).to(device)\n",
    "            distilbert_word_ids = torch.tensor([-100] + item['distilbert_wordids'][1:-1] + [-100]).unsqueeze(0).to(device)\n",
    "            albert_word_ids = torch.tensor([-100] + item['albert_wordids'][1:-1] + [-100]).unsqueeze(0).to(device)\n",
    "            labels = torch.tensor(item['spacy_labels']).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = kingbert_model(distilbert_input_ids, albert_input_ids,\n",
    "                                    distil_attention_mask, alb_attention_mask,\n",
    "                                    distilbert_word_ids, albert_word_ids)\n",
    "\n",
    "            if output.size(0) != labels.size(0):\n",
    "                continue  # skip if shape mismatch due to token alignment\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped example {i} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Save model\n",
    "torch.save(kingbert_model.state_dict(), 'model_state.pth')\n",
    "print('Training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_14972\\3251951415.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('model_state.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KingBert(\n",
       "  (distilbert): DistilBertForTokenClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x TransformerBlock(\n",
       "            (attention): DistilBertSdpaAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=47, bias=True)\n",
       "  )\n",
       "  (albert): AlbertForTokenClassification(\n",
       "    (albert): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertSdpaAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                  (output_dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): NewGELUActivation()\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=47, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KingBert(distilbert_tuned=distilbert_tuned, albert_tuned=albert_tuned)\n",
    "state_dict = torch.load('model_state.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from seqeval.metrics import classification_report as seqeval_classification_report\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_ensemble_model(model, dataset, device=\"cuda\", label_pad_token_id=-100):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i in tqdm(range(len(dataset)), desc=\"Evaluating\"):\n",
    "        try:\n",
    "            item = dataset[i]\n",
    "\n",
    "            # Convert and move to device\n",
    "            d_ids  = torch.tensor(item[\"distilbert_inputids\"]).unsqueeze(0).to(device)\n",
    "            a_ids  = torch.tensor(item[\"albert_inputids\"]).unsqueeze(0).to(device)\n",
    "            d_msk  = torch.tensor(item[\"distilbert_attention_masks\"]).unsqueeze(0).to(device)\n",
    "            a_msk  = torch.tensor(item[\"albert_attention_masks\"]).unsqueeze(0).to(device)\n",
    "            d_wids = torch.tensor([-100] + item[\"distilbert_wordids\"][1:-1] + [-100]).unsqueeze(0).to(device)\n",
    "            a_wids = torch.tensor([-100] + item[\"albert_wordids\"][1:-1] + [-100]).unsqueeze(0).to(device)\n",
    "            labels = torch.tensor(item[\"spacy_labels\"]).unsqueeze(0).to(device)\n",
    "\n",
    "            # Run forward pass\n",
    "            with torch.no_grad():\n",
    "                log_probs = model(d_ids, a_ids, d_msk, a_msk, d_wids, a_wids)  # (1, W, C)\n",
    "\n",
    "            preds = log_probs.argmax(-1)  # (1, W)\n",
    "            preds = preds.squeeze(0)\n",
    "            labels = labels.squeeze(0)\n",
    "\n",
    "            # Truncate to match shortest sequence\n",
    "            min_len = min(len(preds), len(labels))\n",
    "            preds = preds[:min_len]\n",
    "            labels = labels[:min_len]\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy().tolist())\n",
    "            all_labels.append(labels.cpu().numpy().tolist())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped example {i} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # ---- Clean and prepare for evaluation ----\n",
    "    flat_preds = [p for sublist in all_preds for p in sublist if p != label_pad_token_id]\n",
    "    flat_labels = [l for sublist in all_labels for l in sublist if l != label_pad_token_id]\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(flat_labels, flat_preds, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(flat_labels, flat_preds)\n",
    "    return {\n",
    "        \"precision\": np.mean(np.diag(cm) / (cm.sum(0) + 1e-10)),\n",
    "        \"recall\": np.mean(np.diag(cm) / (cm.sum(1) + 1e-10)),\n",
    "        \"f1\": 2 * np.mean(np.diag(cm) / (cm.sum(1) + 1e-10)) * np.mean(np.diag(cm) / (cm.sum(0) + 1e-10)) / (\n",
    "            np.mean(np.diag(cm) / (cm.sum(1) + 1e-10)) + np.mean(np.diag(cm) / (cm.sum(0) + 1e-10)) + 1e-10\n",
    "        ),\n",
    "        \"accuracy\": np.mean(np.array(flat_preds) == np.array(flat_labels)),\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/2320 [00:00<?, ?it/s]c:\\Users\\samue\\Desktop\\nlp-project\\auxiliary.py:259: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  stacked_tensors1 = torch.stack([torch.tensor(i) for i in output1])\n",
      "c:\\Users\\samue\\Desktop\\nlp-project\\auxiliary.py:262: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  stacked_tensors2 = torch.stack([torch.tensor(i) for i in output2])\n",
      "Evaluating:  45%|████▌     | 1048/2320 [00:48<01:06, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 1043 due to error: The size of tensor a (363) must match the size of tensor b (275) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  86%|████████▋ | 2002/2320 [01:30<00:17, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped example 1997 due to error: The size of tensor a (365) must match the size of tensor b (267) at non-singleton dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2320/2320 [01:45<00:00, 22.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       533\n",
      "           1       0.69      0.59      0.64       536\n",
      "           2       0.72      0.80      0.76       772\n",
      "           3       0.74      0.22      0.34       446\n",
      "           4       0.63      0.72      0.67       347\n",
      "           5       0.64      0.53      0.58      1021\n",
      "           6       0.44      0.44      0.44       837\n",
      "           7       0.48      0.80      0.60       654\n",
      "           8       0.65      0.68      0.67       374\n",
      "           9       0.55      0.74      0.63       771\n",
      "          10       0.58      0.46      0.51       887\n",
      "          11       0.83      0.39      0.53       548\n",
      "          12       0.58      0.59      0.58       429\n",
      "          13       0.81      0.77      0.79       204\n",
      "          14       0.46      0.41      0.44       759\n",
      "          15       0.73      0.83      0.78      1631\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.52      0.34      0.41       611\n",
      "          18       0.96      0.97      0.96    188126\n",
      "          19       0.82      0.45      0.58       506\n",
      "          20       0.80      0.51      0.63       718\n",
      "          21       0.43      0.48      0.46       429\n",
      "          22       0.61      0.61      0.61       547\n",
      "          23       0.43      0.45      0.44       693\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.76      0.77      0.77       133\n",
      "          26       0.68      0.73      0.70       775\n",
      "          27       0.62      0.62      0.62       527\n",
      "          28       0.75      0.75      0.75        32\n",
      "          29       0.62      0.61      0.61       454\n",
      "          30       0.85      0.36      0.50       500\n",
      "          31       0.77      0.91      0.84        45\n",
      "          32       0.14      0.08      0.11        12\n",
      "          33       0.63      0.76      0.69      1233\n",
      "          34       0.53      0.48      0.50       529\n",
      "          35       0.76      0.16      0.26       673\n",
      "          36       0.90      0.89      0.90       179\n",
      "          37       0.40      0.41      0.41       185\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.31      0.58      0.40       343\n",
      "          40       0.48      0.49      0.49       510\n",
      "          41       0.20      0.66      0.31        64\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.79      0.87      0.83      1619\n",
      "          44       0.40      0.40      0.40       211\n",
      "\n",
      "    accuracy                           0.93    210418\n",
      "   macro avg       0.57      0.53      0.53    210418\n",
      "weighted avg       0.93      0.93      0.93    210418\n",
      "\n",
      "{'precision': np.float64(0.5666887248953171), 'recall': np.float64(0.5349235374330744), 'f1': np.float64(0.5503481536710766), 'accuracy': np.float64(0.9268456120674087), 'confusion_matrix': array([[ 390,    0,    0, ...,    0,    0,    0],\n",
      "       [   7,  318,    0, ...,    0,    0,    0],\n",
      "       [   0,    0,  615, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   0,    0,    0, ...,    0,    0,    0],\n",
      "       [   0,    0,    0, ...,    0, 1414,    0],\n",
      "       [   0,    0,    0, ...,    0,    0,   85]], shape=(45, 45))}\n"
     ]
    }
   ],
   "source": [
    "test_dataset = aux.json_to_Dataset_ensemble('datasets/ensemble_test.json')\n",
    "\n",
    "\n",
    "res = evaluate_ensemble_model(model, test_dataset)\n",
    "print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
